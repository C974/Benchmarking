Model,Overall_Total,Overall_Correct,Overall_Accuracy,Remember_Total,Remember_Correct,Remember_Accuracy,Understand_Total,Understand_Correct,Understand_Accuracy,Apply_Total,Apply_Correct,Apply_Accuracy,Analyze_Total,Analyze_Correct,Analyze_Accuracy,Evaluate_Total,Evaluate_Correct,Evaluate_Accuracy,Create_Total,Create_Correct,Create_Accuracy
Phi-4-mini-reasoning,222,10,4.504504504504505,40,3,7.5,40,0,0.0,40,1,2.5,40,0,0.0,40,3,7.5,22,3,13.636363636363635
Qwen3-1.7B,222,7,3.153153153153153,40,2,5.0,40,0,0.0,40,0,0.0,40,0,0.0,40,2,5.0,22,3,13.636363636363635
Llama-3.2-1B,222,5,2.2522522522522523,40,3,7.5,40,0,0.0,40,0,0.0,40,0,0.0,40,1,2.5,22,1,4.545454545454546
gemma-3-1b-it,222,5,2.2522522522522523,40,1,2.5,40,0,0.0,40,0,0.0,40,0,0.0,40,2,5.0,22,2,9.090909090909092
DeepSeek-R1-Distill-Qwen-1.5B,222,3,1.3513513513513513,40,1,2.5,40,0,0.0,40,0,0.0,40,0,0.0,40,1,2.5,22,1,4.545454545454546
detailed_benchmark_Qwen1.5-0.5B,222,3,1.3513513513513513,40,1,2.5,40,0,0.0,40,0,0.0,40,0,0.0,40,1,2.5,22,1,4.545454545454546
